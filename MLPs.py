# -*- coding: utf-8 -*-
"""

Automatically generated by Colab.

### Import Packages
"""

import os
import csv
import numpy as np
from tqdm.notebook import tqdm

import matplotlib.pyplot as plt

import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F ##has some useful functions
import torch.optim as optim ##call optimizer
from torch.utils.data import Dataset, DataLoader

print(torch.__version__)

"""### Import your drive's contents"""

from google.colab import drive
drive.mount('/content/drive') ##mounting everything to content and it is needed to save the results of analysis

# Check if the drive has been mounted well.
# !ls ./drive -> What would happen?
model_dir = './drive/MyDrive/docs'

"""### MNIST dataset is provided by default"""

train_path = './sample_data/mnist_train_small.csv'
test_path = './sample_data/mnist_test.csv'
img_size = 28

##csv file contains pixel information from 1 to 255
##you can check the train and test file in the sample_data > mnist
##alternative way
##torchvision.datasets.MNIST

"""### Choose your device"""

# device = 'cpu'
device = 'cuda'
print('Current Device : {}'.format(device))

"""### Read the MNIST dataset
- total 1+ 28x28 dimension. 1 For Label, 28**2 for image

"""

def mnist_reader(file_path, img_size=img_size):
    total_img = list()
    total_label = list()
    with open(file_path) as csvfile:
        mnist_reader = csv.reader(csvfile) ##to read the csv file
        for row in tqdm(mnist_reader): ##tqdm to see the progress
            img = np.array(row[1:], dtype=np.uint16).reshape(img_size, img_size) ##we are transforming the rows into numpy arrays
            img = img / 255 ##to normalize the data > ranging it from 0 to 1
            label = int(row[0])

            total_img.append(img)
            total_label.append(label) ##it is a list now

    total_img = np.asarray(total_img) ##transforming it into a numpy array
    total_label = np.asarray(total_label)

    return total_img, total_label

train_img, train_label = mnist_reader(train_path)
print(train_img.shape, train_label.shape)

train_img, train_label = mnist_reader(train_path)
test_img, test_label = mnist_reader(test_path)

print(test_img.shape, test_label.shape)

# Let's try to reduce the number of data we have.
train_img = train_img[::25] ##20000/5 number of images are selected to reduce the time of computation
train_label = train_label[::25]
test_img = test_img[::25]
test_label = test_label[::25]

print(train_img.shape)
print(test_img.shape)

"""### Define the Dataset"""

class MNIST_Dataset(Dataset):
    def __init__(self, target_img, target_label):
        '''
        target_img : train/test images
        target_label : train/test images
        '''
        self.target_img = target_img # (N, 28, 28)
        self.target_label = target_label # (N)
        self.num_data = len(target_img)

    def __len__(self):
        return self.num_data

    def __getitem__(self, idx):
        curr_img = self.target_img[idx] # 28 28
        curr_label = self.target_label[idx]

        sample = dict()
        sample['img'] = curr_img
        sample['label'] = curr_label

        return sample

"""### Define the DataLoader"""

batch_size = 256

# Define dataset instance for train/test
train_dataset = MNIST_Dataset(train_img, train_label)
test_dataset = MNIST_Dataset(test_img, test_label)

# Define dataloader for train/test
train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)
test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False) ##here shufflign is not mandatory

"""### Try to sample out one data point from dataloader"""

sample = next(iter(test_dataloader))
# Check data's dimension!
print(sample['img'].shape) ##it will automatically stack 256 images (28 by 28)
print(sample['label'].shape)

# Try to plot the sample image
plt.imshow(sample["img"][0])
plt.title('Label: {}'.format(sample['label'][0]))
plt.show()

"""### Define the Multiple Layer Perceptrons"""

class MLPs(nn.Module):
    def __init__(self, dim_hidden_1, dim_hidden_2, dim_input=img_size**2, dim_output=10):
        super(MLPs, self).__init__()

        self.dim_hidden_1 = dim_hidden_1
        self.dim_hidden_2 = dim_hidden_2
        self.dim_input = dim_input
        self.dim_output = dim_output

        self.layer_1 = nn.Linear(dim_input, dim_hidden_1)
        self.layer_2 = nn.Linear(dim_hidden_1, dim_hidden_2)
        self.layer_3 = nn.Linear(dim_hidden_2, dim_output)

        self.activation = nn.ReLU()
        # self.dropout = nn.Dropout(0.5)

    def forward(self, img):
        batch_size = img.shape[0]
        input = img.view(batch_size, -1)

        # Try to use Dropout after the activation
        hidden_1 = self.activation(self.layer_1(input))
        hidden_2 = self.activation(self.layer_2(hidden_1))
        out = self.layer_3(hidden_2)

        return out

"""### Define the Model and optimizer"""

# Define the Model, and put it to the device.
model = MLPs(dim_hidden_1 = 512, dim_hidden_2 = 256)
model = model.to(device) ##copy model to device GPU

# Define the optimizer
optimizer = optim.Adam(model.parameters(), lr = 0.0001) ##callign optimizer
print(model)

"""### Define functions for train/test"""

def train(model, optimizer, sample):
    model.train()

    # Define the Loss
    criterion = nn.CrossEntropyLoss()

    # Clean up the Optimizer
    optimizer.zero_grad() ##gradient should be cleaned up, otherwise it will be stacked

    # Set Input and Output
    img = sample['img'].float().to(device)
    label = sample['label'].long().to(device)

    # Get prediction from the model
    pred = model(img)

    # Calculate number of correct prediction.
    num_correct = sum(torch.argmax(pred, dim=1) == label)

    # Get the Loss from prediction and ground truth label
    pred_loss = criterion(pred, label)

    # Get the gradient, and run optimizer for one step.
    pred_loss.backward()
    optimizer.step()

    return pred_loss.item(), num_correct.item()

def test(model, sample):
    model.eval()

    # Define the Loss
    criterion = nn.CrossEntropyLoss()

    # Get the result without computing the gradient
    with torch.no_grad():
        # Set input and output
        img = sample['img'].float().to(device)
        label = sample['label'].long().to(device)

        # Get prediction from the model
        pred = model(img)
        pred_loss = criterion(pred, label)

        # Calculate number of correct prediction.
        num_correct = sum(torch.argmax(pred, dim=1) == label)


    return pred_loss.item(), num_correct.item()

"""### Run Training"""

max_epoch = 200
tmp_path = './checkpoint.pth'

for epoch in tqdm(range(max_epoch)):
    ###Train Phase

    # Initialize Loss and Accuracy
    train_loss = 0.0
    train_accu = 0.0

    # Iterate over the train_dataloader
    for idx, sample in enumerate(train_dataloader):
        curr_loss, num_correct = train(model, optimizer, sample)
        train_loss += curr_loss / len(train_dataloader)
        train_accu += num_correct / len(train_dataset)

    # Try to save the model to your drive
    torch.save(model.state_dict(), 'recent.pth')

    ### Test Phase
    # Initialize Loss and Accuracy
    test_loss = 0.0
    test_accu = 0.0

    # Iterate over the test_dataloader
    for idx, sample in enumerate(test_dataloader):
        curr_loss, num_correct = test(model, sample)
        test_loss += curr_loss / len(test_dataloader)
        test_accu += num_correct / len(test_dataset)

    print('[EPOCH {}]: TR LOSS: {:.2f}, TEST ACCU: {:.2f} '.format(epoch+1,
                                                               train_accu,
                                                               test_accu))

